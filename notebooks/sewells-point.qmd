# Water Levels at Sewell's Point, VA {.unnumbered}

```{julia}
using CairoMakie
using CSV
using DataFrames
using Dates
using Distributions
using DynamicHMC
using LaTeXStrings
using Turing
using Unitful
```

## Read data

```{julia}
function read_tides(year::Int)
    fname = "data/8638610/tidesandcurrents-8638610-$(year)-NAVD-GMT-metric.csv"
    date_format = "yyyy-mm-dd HH:MM"
    df = CSV.read(fname, DataFrame; dateformat=date_format)
    df[!, " Water Level"] .*= u"m"
    rename!(df, " Water Level" => "water_level", "Date Time" => "datetime")
    return df[!, ["datetime", "water_level"]]
end

# print out the first 10 rows of the 1928 data
hourly = vcat([read_tides(year) for year in 1928:2021]...)
dropmissing!(hourly)
first(hourly, 5)
```

Convert to annual maximums

```{julia}
# Convert hourly data to annual maximums
hourly[!, :year] = year.(hourly.datetime)
annmax = combine(
    groupby(hourly, :year),
    :water_level => maximum => :lsl
)

annmax.lsl_ft = ustrip.(u"ft", annmax.lsl)
first(annmax, 5)
```

```{julia}
#| code-fold: true
fig = Figure(; size=(800, 400))

# Time series plot
ax1 = Axis(
    fig[1, 1];
    xlabel="Year",
    ylabel="Ann. Max. Water Level [ft]",
)
scatter!(ax1, annmax.year, annmax.lsl_ft)

# Histogram
ax2 = Axis(
    fig[1, 2];
    ylabel="",
    yticklabelsvisible=false,
)

# Create horizontal histogram directly
hist!(
    ax2,
    annmax.lsl_ft;
    direction=:x,  # Make bars go horizontally
    bins=range(2, 8, 20),
    normalization=:pdf
)

# Link y axes and set limits
linkyaxes!(ax1, ax2)
ylims!(ax1, 2, 8)
xlims!(ax2, 0, 0.8)

# Add title
Label(fig[0, :], "Sewell's Point, VA"; fontsize=20)

fig
```

## Model {.scrollable}

Define a LogNormal distribution with very diffuse (flat) priors

```{julia}
#| output: false
@model function lognormal_flatpriors(y)
    # define the parameters
    # and assign prior
    μ ~ Normal(0, 10) # Extremely diffuse prior
    σ ~ truncated(Normal(0, 10), 0, Inf) # σ must be positive

    # data generating process
    return y .~ LogNormal(μ, σ)
end
```

## Sample

```{julia}
#| output: false
ln_flat_chn = let
    model = lognormal_flatpriors(annmax.lsl_ft)
    sampler = externalsampler(DynamicHMC.NUTS())
    nsamples = 20_000
    sample(model, sampler, nsamples; drop_warmup=true)
end
summarystats(ln_flat_chn)
```

## Posterior

We leverage the `histogram2d` function to visualize the 2D posterior distribution.

```{julia}
#| code-fold: true
post1_scatter = let
    fig = Figure(size=(800, 600))
    ax = Axis(fig[1, 1], title="Diffuse Priors", xlabel=L"\mu", ylabel=L"\sigma")
    scatter!(ax, ln_flat_chn[:μ][:], ln_flat_chn[:σ][:], color=:blue, markersize=2, label=false)
    fig
end
```

## Return period with uncertainty

Each draw from the posterior represents a plausible value of $\mu$ and $\sigma$.
We can use these to explore the distribution of return periods.

```{julia}
#| include: false
#| output: false
#| code-fold: true
# Return period with uncertainty
rts = exp.(range(log(1.25), log(500); length=500)) # return periods
aeps = 1 .- 1 ./ rts # annual exceedance probability

xticks = [2, 5, 10, 25, 50, 100, 250, 500]
yticks = 2:9

plt_rt_base = let
    fig = Figure(size=(800, 600))
    ax = Axis(fig[1, 1], title="Return Period with Uncertainty", xlabel="Return Period [years]", ylabel="Return Level [ft]", xscale=log10, yscale=log10)
    ax.xticks = (xticks, string.(xticks))
    ax.yticks = (yticks, string.(yticks))
    fig
end

function weibull_plot_pos(y)
    N = length(y)
    ys = sort(y; rev=false) # sorted values of y
    nxp = xp = [r / (N + 1) for r in 1:N] # exceedance probability
    xp = 1 .- nxp
    return xp, ys
end

plt_rt = let
    xp, ys = weibull_plot_pos(annmax.lsl_ft)

    fig = plt_rt_base
    ax = fig[1, 1]
    scatter!(ax, 1 ./ xp, ys, label="Observations", color=:gray, alpha=1)
    for idx in 1:500
        μ = ln_flat_chn[:μ][idx]
        σ = ln_flat_chn[:σ][idx]
        rt = quantile.(LogNormal(μ, σ), aeps)
        label = idx == 1 ? "Posterior" : false
        lines!(ax, rts, rt, color=:black, alpha=0.05, label=label, linewidth=0.5)
    end
    fig
end
```

## Trace plot {.scrollable}

Visualize the samples as a *chain*

```{julia}
let
    μ_trace = ln_flat_chn[:μ]
    σ_trace = ln_flat_chn[:σ]

    fig = Figure(size=(800, 600))

    # Plot for μ
    ax1 = Axis(fig[1, 1], title="Trace Plot for μ", xlabel="Iteration", ylabel=L"\mu")
    lines!(ax1, μ_trace[:], color=:blue, linewidth=0.25)

    # Plot for σ
    ax2 = Axis(fig[2, 1], title="Trace Plot for σ", xlabel="Iteration", ylabel=L"\sigma")
    lines!(ax2, σ_trace[:], color=:red, linewidth=0.25)

    fig
end
```

# Alternative priors

## Model {.scrollable}

We can treat the priors as parameters so that we don't have to define a new `@model` each time we want to update our priors

```{julia}
#| output: false
@model function lognormal(y, μ_dist, σ_dist) # <1>
    μ ~ μ_dist
    σ ~ σ_dist
    return y .~ LogNormal(μ, σ)
end
```

1. No reason why we can't pass distributions as functional arguments

## Guess and prior predictive check {.scrollable}

Define priors

```{julia}
#| output: false
μ_prior = Normal(3, 3)
σ_prior = truncated(Normal(0, 3), 0, Inf)
```

Draw samples from the prior

```{julia}
#| output: false
ln_ppc = let
    model = lognormal(annmax.lsl_ft, μ_prior, σ_prior)
    sampler = Prior()
    nsamples = 10_000
    sample(model, sampler, nsamples; drop_warmup=true)
end
```

Plot the consequences of these samples

```{julia}
#| code-fold: true
plt_prior_1 = let
    fig = Figure(size=(800, 600))
    ax = Axis(fig[1, 1], title="Prior Predictive Check", xlabel="Return Period [years]", ylabel="Return Level [ft]", xscale=log10, yscale=log10)
    ax.xticks = (xticks, string.(xticks))
    ax.yticks = (yticks, string.(yticks))
    for idx in 1:1_000
        μ = ln_ppc[:μ][idx]
        σ = ln_ppc[:σ][idx]
        rt = quantile.(LogNormal(μ, σ), aeps)
        label = idx == 1 ? "Prior" : false
        lines!(ax, rts, rt, color=:black, alpha=0.1, label=label)
    end
    fig
end
```

## Revise

If we are getting return levels of $10^{12}$ ft, we should probably revise our priors

```{julia}
#| output: false
μ_prior = Normal(1, 1) # <1>
σ_prior = truncated(Normal(0, 1), 0, Inf)
```

1. Yes, I'm overwriting the old value

We can sample

```{julia}
#| output: false
#| code-fold: true
ln_ppc = let
    model = lognormal(annmax.lsl_ft, μ_prior, σ_prior)
    sampler = Prior()
    nsamples = 10_000
    sample(model, sampler, nsamples; drop_warmup=true)
end

plt_prior_2 = let
    fig = Figure(size=(800, 600))
    ax = Axis(fig[1, 1], title="Revised Prior Predictive Check", xlabel="Return Period [years]", ylabel="Return Level [ft]", xscale=log10, yscale=log10)
    ax.xticks = (xticks, string.(xticks))
    ax.yticks = (yticks, string.(yticks))
    for idx in 1:1_000
        μ = ln_ppc[:μ][idx]
        σ = ln_ppc[:σ][idx]
        rt = quantile.(LogNormal(μ, σ), aeps)
        label = idx == 1 ? "Prior" : false
        lines!(ax, rts, rt, color=:black, alpha=0.1, label=label)
    end
    fig
end
```

## Getting closer

```{julia}
#| output: false
μ_prior = Normal(1, 1) # <1>
σ_prior = truncated(Normal(0, 0.5), 0, Inf)
```

```{julia}
#| code-fold: true
ln_ppc = let
    model = lognormal(annmax.lsl_ft, μ_prior, σ_prior)
    sampler = Prior()
    nsamples = 5000
    sample(model, sampler, nsamples; drop_warmup=true)
end

plt_prior_3 = let
    fig = Figure(size=(800, 600))
    ax = Axis(fig[1, 1], title="Closer Prior Predictive Check", xlabel="Return Period [years]", ylabel="Return Level [ft]", xscale=log10, yscale=log10)
    ax.xticks = (xticks, string.(xticks))
    ax.yticks = (yticks, string.(yticks))
    for idx in 1:1_000
        μ = ln_ppc[:μ][idx]
        σ = ln_ppc[:σ][idx]
        rt = quantile.(LogNormal(μ, σ), aeps)
        label = idx == 1 ? "Prior" : false
        lines!(ax, rts, rt, color=:black, alpha=0.1, label=label)
    end
    fig
end
```

## Now get posterior {.scrollable}

We use the same model to get the posterior.
Often we want to run multiple chains with different initial values to make sure we are getting good samples.

```{julia}
#| output: false
ln_post = let
    model = lognormal(annmax.lsl_ft, μ_prior, σ_prior)
    sampler = externalsampler(DynamicHMC.NUTS())
    n_per_chain = 5000
    nchains = 4
    sample(model, sampler, MCMCThreads(), n_per_chain, nchains; drop_warmup=true)
end
```

```{julia}
summarystats(ln_post)
```

## Traceplot for multiple chains

```{julia}
let
    fig = Figure(size=(800, 600))
    ax1 = Axis(fig[1, 1], title="Trace Plot for μ", xlabel="Iteration", ylabel=L"\mu")
    lines!(ax1, vec(ln_post[:μ]), color=:blue, linewidth=0.25)
    ax2 = Axis(fig[2, 1], title="Trace Plot for σ", xlabel="Iteration", ylabel=L"\sigma")
    lines!(ax2, vec(ln_post[:σ]), color=:red, linewidth=0.25)
    fig
end
```

## Visualize {.scrollable}

```{julia}
#| code-fold: true
post2_scatter = let
    fig = Figure(size=(800, 600))
    ax1 = Axis(fig[1, 1], title="More informed priors", xlabel=L"\mu", ylabel=L"\sigma")
    scatter!(ax1, vec(ln_post[:μ]), vec(ln_post[:σ]))
    fig
end
post2_scatter
```

::: {.callout-note}
Here our likelihood is very informative, so it doesn't much matter if we use excessively diffuse priors.
This is nice, though not something we can count on in general.
:::

## Return period with uncertainty

As before, we can visualize our posterior distribution in terms of return periods

```{julia}
#| code-fold: true
plt_rt = let
    fig = Figure(size=(800, 600))
    ax = Axis(fig[1, 1], title="Return Period with Uncertainty", xlabel="Return Period [years]", ylabel="Return Level [ft]", xscale=log10, yscale=log10)
    ax.xticks = (xticks, string.(xticks))
    ax.yticks = (yticks, string.(yticks))
    scatter!(ax, 1 ./ xp, ys; label="Observations", color=:gray, alpha=1)
    for idx in 1:500
        μ = ln_post[:μ][idx]
        σ = ln_post[:σ][idx]
        rt = quantile.(LogNormal(μ, σ), aeps)
        label = idx == 1 ? "Posterior" : false
        lines!(ax, rts, rt, color=:black, alpha=0.05, label=label)
    end
    fig
end
plt_rt