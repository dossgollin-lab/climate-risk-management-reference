# Statistics Without the Agonizing Details {.unnumbered}

In this class we will use computation and simulation to build fundamental insight into statistical processes without dwelling on "agonizing" details.
Here we implement the excellent example problem from John Rauser.
First, watch the video:

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/5Dnw46eC-0o?si=3Y3JKwkwD9i6lrVV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

We will recreate his analysis to answer the fundamental question:

> Does drinking beer reduce the likelihood of being bitten by mosquitos?

## Data

First, we will create the data.
Here is the data for the beer drinkers:

```{julia}
#| output: false
#| code-fold: true
beer = [
    27,
    20,
    21,
    26,
    27,
    31,
    24,
    21,
    20,
    19,
    23,
    24,
    28,
    19,
    24,
    29,
    18,
    20,
    17,
    31,
    20,
    25,
    28,
    21,
    27,
]
```

Using Julia, we can learn more about the data through exploratory analysis.

```{julia}
typeof(beer)
```

```{julia}
length(beer)
```

```{julia}
size(beer)
```

```{julia}
sum(beer) / length(beer) # the sample average
```

We can do the same for water drinkers:

```{julia}
#| code-fold: true
#| output: false
water = [21, 22, 15, 12, 21, 16, 19, 15, 22, 24, 19, 23, 13, 22, 20, 24, 18, 20]
```

## A simple analysis

Following Rauser, let's calculate the difference between the average number of bites in each group.
Let's calculate the difference between the average number of bites in each group.

```{julia}
#| output: false
using StatsBase: mean # <1>
```
1. This gives us the `mean` function from the `StatsBase` package

```{julia}
observed_diff = mean(beer) - mean(water)
observed_diff
```

## The skeptic's argument

The skeptic asks whether this might be random chance.

1. We could answer this with a $T$ test:
    1. Determine if there is a significant difference between the means of two groups
    1. Assumes (approximate) normality
    1. Assumptions hidden behind a software package
1. Simulation approach:
    1. Suppose the skeptic is right -- the two groups are samped from the same distribution
    1. Shuffle the data (randomly divide into two groups by assuming that there is no difference between the two groups)
    1. Calculate the difference between each group
    1. Repeat many times and examine the distribution of differences

### Implementation {.smaller}

We can code up the simulation approach in Julia.

```{julia}
#| output: false
using Random: shuffle # <1>
```
1. This gives us the `shuffle` function from the `Random` package

```{julia}
function get_shuffled_difference(y1, y2) # <1>

    # concatenate the data into one vector, then shuffle it
    y_all = vcat(y1, y2)
    y_shuffled = shuffle(y_all)

    # create groups consistent w/ skeptic's argument
    N1 = length(y1) # how many obs in the first vector?
    ynew1 = y_shuffled[1:N1]
    ynew2 = y_shuffled[(N1+1):end]

    # get the difference
    difference = mean(ynew1) - mean(ynew2)
    return difference
end # <2>

get_shuffled_difference(beer, water) # <3>
```
1. Define a function. Its arguments are `y1` and `y2`
2. `end` closes the function definition
3. Call the function with our data

### Running

We want to learn about the *sampling distribution* of the group differences: repeat this experiment many times over and plot the results.

```{julia}
simulated_diffs = [get_shuffled_difference(beer, water) for i in 1:50_000] # <1>
length(simulated_diffs) # <2>
```

1. This is a *list comprehension*. It's a way to create a list by looping over something. Here, we loop over the numbers 1 to 50,000 and call `get_shuffled_difference` each time.
2. `length` tells us the size of a vector

### Plotting

```{julia}
using Plots
```
1. We need the `Plots` package to make plots

```{julia}
function plot_diffs(diffs, obs) # <2>
    p = histogram( # <3>
        diffs; # <4>
        xlabel="Difference", # <5>
        ylabel="Proportion of samples", # <6>
        label="If Skeptic is Right", # <7>
        bins=-6:0.5:6, # <8>
        legend=:topleft, # <9>
        normalize=true, # <10>
    )
    vline!(p, [obs]; label="Observed", linewidth=2) # <11>
    return p # <12>
end
plot_diffs(simulated_diffs, observed_diff)
```

2. Define a function. Its arguments are `diffs` and `obs`
3. `histogram` is a function from the `Plots` package
4. Create a histogram using the `diffs` object. `;` separates the positional arguments from the keyword arguments
5. `xlabel` is a "keyword argument" specifying the text for the x-axis label
6. the y-axis label
7. the label to use in the legend
8. specify the bins to use in the histogram
9. specify the location of the legend
10. normalize the histogram so that the area under the curve is 1
11. add a vertical line (`vline!`) at the observed difference
12. many functions *return* their output -- in this case the plot we created from the inputs

### Alternative

We could have done this with a parametric test

```{julia}
using HypothesisTests 
```

```{julia}
t1 = HypothesisTests.EqualVarianceTTest(beer, water) # <1>
t2 = HypothesisTests.UnequalVarianceTTest(beer, water); # <2>
```

1. We don't need to include the `HypothesisTests.`, but it adds clarity
2. Recall: `;` suppresses output

:::: {.columns}
::: {.column width="50%"}

```{julia}
t1
```

:::
::: {.column width="50%"}

```{julia}
t2
```

:::
::::


```{julia}
mean(simulated_diffs .>= observed_diff) # <1>
```
1. `.` is the *dot operator*. It applies the function to each element of the vector individually.

