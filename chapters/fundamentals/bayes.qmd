---
title: Bayesian Utility and Inference
---

::: {.callout-note}
## Under Construction
This chapter is still under active construction. Please check back regularly for updates and new content.
:::

## Learning Objectives {.unnumbered}

- Articulate why parametric uncertainty is important for climate risk management
- Use Markov Chain Monte Carlo (MCMC) techniques to estimate posterior distributions.
- Understand the role of utility theory in decision-making under uncertainty.

## Bayesian Utility Theory

We will often be interested in making decisions despite not having perfect information.

### Types of uncertainty

- Aleatory uncertainty: inherent variability in the system (ie, randomness)
- Epistemic uncertainty: uncertainty in our knowledge of the system, often useful to divide into
    - Parametric uncertainty (what we will use here)
    - Model structure uncertainty (treated qualitatively)

### History

- First conceived as a way to try to explain human behavior
    - Turns out not to be a great model -- people do not always behave rationally

### Utility

- Some function that we want to maximize
- Alternatively can be thought of as a cost function that we want to minimize
- $U(a, \theta)$
    - $a$ is the action we take
    - $\theta$ is the state of the world

### Expected Utility

$$
\mathbb{E} \left[ U(a, \theta) \right] = \int_{\theta \in \Theta} U(a, \theta) p(\theta) d\theta
$$

or in the discrete case

$$
\mathbb{E} \left[ U(a, \theta) \right] = \sum_{\theta \in \Theta} U(a, \theta) p(\theta)
$$

## Bayesian Inference

1. Parameters have **probability distributions**, not single point values 
1. Start with some prior distribution for parameters
1. Goal: what is the distribution of the parameters given the data?

Builds on Bayes' Theorem.
Bayes' rule for distributions.

$$
p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{p(y)}
$$

If we are drawing samples from a distribution, we can calculate up to a constant of proportionality and  -- since $p(y)$ doesn't depend on $\theta$ -- we can usually ignore it.

$$
\overbrace{p(\theta \mid y)}^\rm{posterior} \propto \underbrace{p(y \mid \theta)}_\rm{likelihood} \overbrace{p(\theta)}^\rm{prior}
$$


## Maximum A Posteriori (MAP) Estimation

## MCMC Methods

## Hierarchical Models

## Missing Data

## Censored Data

## Bayesian Workflow and Philosophy

### Priors

The posterior is a compromise between the prior and the likelihood.

- Bad priors lead to bad inferences
- The choice of prior is subjective, which some people hate,
    - We will approach this in a principled manner [@gelman_philosophy:2013;@gelman_workflow:2020]
    - Lots of other steps are also subjective (choice of likelihood model, which data to use, problem framing, etc)
    - False sense of objectivity is dangerous anyways!

## Further Reading

- Although about a decade old, @gelman_bda3:2014 is the definitive reference for Bayesian statistics
- @mcelreath_rethinking2:2020 takes a different pedagogical approach to @gelman_bda3:2014, covering similar concepts from a somewhat more applied perspective. Lectures are available [on YouTube](https://www.youtube.com/@rmcelreath).
- @gelman_workflow:2020 is a mini-textbook on Bayesian workflow
- @gelman_subjectiveobjective:2017 and @gelman_workflow:2020 cleanly outline how to think about interpreting probability -- which is often misunderstood.

