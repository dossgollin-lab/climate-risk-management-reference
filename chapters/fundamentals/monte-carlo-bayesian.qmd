---
title: "Bayesian Inference and MCMC: Computational Examples ðŸš§"
---

This companion file provides computational examples for Bayesian inference concepts covered in the [Monte Carlo Methods](/chapters/fundamentals/monte-carlo.qmd) chapter.

```{julia}
#| echo: false
#| output: false
using CairoMakie
using CSV
using DataFrames
using Distributions
using DynamicHMC
using LaTeXStrings
using MCMCChains
using Optim
using Turing
using Random
Random.seed!(123)
CairoMakie.activate!(; type = "svg")
```

## Bayes' Theorem Fundamentals

### The Rare Disease Problem

A classic example to illustrate the importance of prior information:

1. Everyone is tested for a rare disease affecting 1 in 1,000 people
2. The test is 99% accurate  
3. Your test comes back positive. What is the probability you have the disease?

```{julia}
accuracy = 0.99
pr_disease = 0.001  # p(Î¸ = 1)

# Calculate p(positive test)
pr_positive_test = accuracy * pr_disease + (1 - accuracy) * (1 - pr_disease)

# Apply Bayes' rule: p(disease | positive) 
pr_disease_given_test = accuracy * pr_disease / pr_positive_test

println("Prior probability of disease: $(round(pr_disease, digits=4))")
println("Probability of positive test: $(round(pr_positive_test, digits=4))")
println("Posterior probability of disease: $(round(pr_disease_given_test, digits=4))")
```

Despite the 99% accurate test, the probability of having the disease given a positive test is only about 9%! This demonstrates the crucial role of prior information.

## Bayesian Parameter Estimation

### Coin Flipping Example

We flip a coin several times and want to estimate the probability of heads.

```{julia}
# Observed data
coin_flips = ["H", "H", "H", "T", "H", "H", "H", "H", "H"]
heads = [flip == "H" for flip in coin_flips]
N = length(coin_flips)
n_heads = sum(heads)

println("Observed: $n_heads heads out of $N flips")
```

### Maximum Likelihood Estimate

```{julia}
# Log-likelihood function
flip_log_like(Î¸) = sum(logpdf.(Bernoulli(Î¸), heads))

# Find MLE
loss(Î¸) = -flip_log_like(Î¸)
Î¸_mle = optimize(loss, 0, 1).minimizer

# Plot likelihood
Î¸_range = 0.1:0.01:1.0
likelihood = [exp(flip_log_like(Î¸)) for Î¸ in Î¸_range]

fig = lines(Î¸_range, likelihood;
	axis = (xlabel = "Î¸", ylabel = "Likelihood", title = "Likelihood Function"))
vlines!([Î¸_mle], color = :red, linewidth = 2, label = "MLE")
axislegend()
fig
```

### Bayesian Analysis with Beta Prior

```{julia}
# Choose Beta prior
prior_dist = Beta(5, 5)

# The posterior for Beta-Binomial is analytically known
posterior_dist = Beta(prior_dist.Î± + n_heads, prior_dist.Î² + N - n_heads)

# Plot prior, likelihood, and posterior
Î¸_fine = 0:0.01:1
fig = lines(Î¸_fine, pdf.(prior_dist, Î¸_fine),
	label = "Prior", linewidth = 2,
	axis = (xlabel = "Î¸", ylabel = "Density", title = "Bayesian Coin Flip Analysis"))

likelihood_normalized = [exp(flip_log_like(Î¸)) for Î¸ in Î¸_fine]
likelihood_normalized = likelihood_normalized ./ maximum(likelihood_normalized) .* maximum(pdf.(prior_dist, Î¸_fine))
lines!(Î¸_fine, likelihood_normalized, label = "Likelihood (scaled)", linewidth = 2)

lines!(Î¸_fine, pdf.(posterior_dist, Î¸_fine),
	label = "Posterior", linewidth = 2)

vlines!([Î¸_mle], color = :red, linewidth = 2, linestyle = :dash, label = "MLE")
axislegend()
fig
```

## Markov Chain Monte Carlo (MCMC)

### Simple Metropolis-Hastings Algorithm

```{julia}
# Define log posterior
log_posterior(Î¸) = logpdf(prior_dist, Î¸) + flip_log_like(Î¸)

# Simple Metropolis-Hastings sampler
function simple_mcmc(n_samples; initial_Î¸ = 0.5)
	samples = Float64[]
	current_Î¸ = initial_Î¸

	for i in 1:n_samples
		# Propose new value from uniform distribution
		proposal = rand(Uniform(0, 1))

		# Calculate acceptance probability
		log_Î± = log_posterior(proposal) - log_posterior(current_Î¸)
		Î± = min(1, exp(log_Î±))

		# Accept or reject
		if rand() < Î±
			current_Î¸ = proposal
		end

		push!(samples, current_Î¸)
	end

	return samples
end

# Run sampler
mcmc_samples = simple_mcmc(10_000)

# Compare with analytical solution
fig = hist(mcmc_samples, bins = 50, normalization = :pdf,
	label = "MCMC Samples",
	axis = (xlabel = "Î¸", ylabel = "Density", title = "MCMC vs Analytical Posterior"))

Î¸_plot = 0:0.001:1
lines!(Î¸_plot, pdf.(posterior_dist, Î¸_plot),
	linewidth = 3, label = "Analytical Posterior")
axislegend()
fig
```

## Turing.jl for Modern Bayesian Inference

### Model Specification

```{julia}
# Define Bayesian model in Turing
@model function coinflip_model(y)
	# Prior
	Î¸ ~ Beta(5, 5)

	# Likelihood  
	y .~ Bernoulli(Î¸)
end

# Sample from posterior
model = coinflip_model(heads)
chain = sample(model, NUTS(), 2_000)

summarystats(chain)
```

### Visualization

```{julia}
# Extract samples
Î¸_samples = chain[:Î¸]

fig = hist(Î¸_samples, bins = 50, normalization = :pdf,
	label = "Turing Samples",
	axis = (xlabel = "Î¸", ylabel = "Density", title = "Turing.jl vs Analytical Posterior"))

lines!(Î¸_plot, pdf.(posterior_dist, Î¸_plot),
	linewidth = 3, label = "Analytical Posterior")
axislegend()
fig
```

## Case study: Storm Surge Distribution

This example demonstrates Bayesian inference for continuous parameters using real climate data.

### Data preparation  

```{julia}
# Create synthetic storm surge data (representing annual maxima)
Random.seed!(456)
true_Î¼ = 1.2
true_Ïƒ = 0.3
n_years = 30

# Generate synthetic data
surge_data = rand(LogNormal(true_Î¼, true_Ïƒ), n_years)

fig = scatter(1:n_years, surge_data,
	axis = (xlabel = "Year", ylabel = "Annual Max Surge Height (m)",
		title = "Synthetic Storm Surge Data"))
```

### Bayesian Model

```{julia}
# Define Bayesian model for LogNormal distribution
@model function lognormal_model(y, Î¼_prior, Ïƒ_prior)
	Î¼ ~ Î¼_prior
	Ïƒ ~ Ïƒ_prior

	y .~ LogNormal(Î¼, Ïƒ)
end
```

### Prior Predictive Checks

```{julia}
# Start with diffuse priors
Î¼_prior = Normal(0, 10)
Ïƒ_prior = truncated(Normal(0, 10), 0, Inf)

# Sample from prior predictive distribution
prior_samples = sample(lognormal_model(surge_data, Î¼_prior, Ïƒ_prior), Prior(), 1_000)

# Plot some prior predictive realizations
fig = lines(1:n_years, surge_data, linewidth = 3, label = "Observed Data",
	axis = (xlabel = "Year", ylabel = "Surge Height (m)",
		title = "Prior Predictive Checks"))

for i in 1:10
	Î¼_sample = prior_samples[:Î¼][i]
	Ïƒ_sample = prior_samples[:Ïƒ][i]
	simulated = rand(LogNormal(Î¼_sample, Ïƒ_sample), n_years)
	lines!(1:n_years, simulated, color = (:blue, 0.3), linewidth = 1)
end

# Add label for simulated data
lines!(1:n_years, rand(LogNormal(prior_samples[:Î¼][1], prior_samples[:Ïƒ][1]), n_years),
	color = (:blue, 0.3), linewidth = 1, label = "Prior Predictive")
axislegend()
fig
```

### Posterior Inference

```{julia}
# Use more informative priors based on domain knowledge
Î¼_prior_informed = Normal(1, 1)
Ïƒ_prior_informed = truncated(Normal(0, 0.5), 0, Inf)

# Sample posterior
model = lognormal_model(surge_data, Î¼_prior_informed, Ïƒ_prior_informed)
posterior_chain = sample(model, NUTS(), 2_000)

summarystats(posterior_chain)
```

### Return period analysis with Uncertainty

```{julia}
# Calculate return levels with uncertainty
return_periods = [2, 5, 10, 25, 50, 100]
exceedance_probs = 1 .- 1 ./ return_periods

# Extract posterior samples
Î¼_posterior = posterior_chain[:Î¼]
Ïƒ_posterior = posterior_chain[:Ïƒ]

# Calculate return level distributions
return_level_samples = []
for (i, aep) in enumerate(exceedance_probs)
	levels = [quantile(LogNormal(Î¼_posterior[j], Ïƒ_posterior[j]), aep)
			  for j in 1:length(Î¼_posterior)]
	push!(return_level_samples, levels)
end

# Plot return level uncertainty
fig = scatter(return_periods, [quantile(levels, 0.5) for levels in return_level_samples],
	axis = (xlabel = "Return Period (years)", ylabel = "Return Level (m)",
		title = "Return Levels with Uncertainty", xscale = log10),
	label = "Median", markersize = 8)

# Add uncertainty bands  
for (i, levels) in enumerate(return_level_samples)
	lower = quantile(levels, 0.1)
	upper = quantile(levels, 0.9)
	# Add error bars
	scatter!([return_periods[i]], [quantile(levels, 0.5)],
		yerror = [quantile(levels, 0.5) - lower, upper - quantile(levels, 0.5)],
		color = :blue, alpha = 0.5)
end

# Add true values for comparison
true_levels = [quantile(LogNormal(true_Î¼, true_Ïƒ), aep) for aep in exceedance_probs]
lines!(return_periods, true_levels, color = :red, linewidth = 2, label = "True Values")

axislegend()
fig
```

## Key Takeaways

1. **Prior Information Matters**: The rare disease example shows how prior probabilities dramatically affect conclusions
2. **MCMC Enables Complex Inference**: Modern samplers like NUTS can handle high-dimensional, complex posterior distributions
3. **Model Checking is Crucial**: Prior predictive checks help validate model assumptions
4. **Uncertainty Quantification**: Bayesian methods naturally quantify parameter uncertainty, crucial for risk analysis
5. **Computational Tools**: Turing.jl provides a powerful, flexible framework for Bayesian modeling

The combination of principled uncertainty quantification and modern computational tools makes Bayesian methods particularly valuable for climate risk assessment.