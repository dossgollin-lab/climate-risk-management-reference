---
title: "Bayesian Inference and MCMC: Computational Examples ✏️"
---

This companion file provides computational examples for Bayesian inference concepts covered in the [Monte Carlo Methods](/chapters/fundamentals/monte-carlo.qmd) chapter.

```{julia}
#| echo: false
#| output: false
using CairoMakie
using CSV
using DataFrames
using Distributions
using DynamicHMC
using LaTeXStrings
using MCMCChains
using Optim
using Turing
using Random
Random.seed!(123)
CairoMakie.activate!(; type = "svg")
```

## Bayes' Theorem Fundamentals

### The Rare Disease Problem

A classic example to illustrate the importance of prior information:

1. Everyone is tested for a rare disease affecting 1 in 1,000 people
2. The test is 99% accurate  
3. Your test comes back positive. What is the probability you have the disease?

```{julia}
accuracy = 0.99
pr_disease = 0.001  # p(θ = 1)

# Calculate p(positive test)
pr_positive_test = accuracy * pr_disease + (1 - accuracy) * (1 - pr_disease)

# Apply Bayes' rule: p(disease | positive) 
pr_disease_given_test = accuracy * pr_disease / pr_positive_test

println("Prior probability of disease: $(round(pr_disease, digits=4))")
println("Probability of positive test: $(round(pr_positive_test, digits=4))")
println("Posterior probability of disease: $(round(pr_disease_given_test, digits=4))")
```

Despite the 99% accurate test, the probability of having the disease given a positive test is only about 9%! This demonstrates the crucial role of prior information.

## Bayesian Parameter Estimation

### Coin Flipping Example

We flip a coin several times and want to estimate the probability of heads.

```{julia}
# Observed data
coin_flips = ["H", "H", "H", "T", "H", "H", "H", "H", "H"]
heads = [flip == "H" for flip in coin_flips]
N = length(coin_flips)
n_heads = sum(heads)

println("Observed: $n_heads heads out of $N flips")
```

### Maximum Likelihood Estimate

```{julia}
# Log-likelihood function
flip_log_like(θ) = sum(logpdf.(Bernoulli(θ), heads))

# Find MLE
loss(θ) = -flip_log_like(θ)
θ_mle = optimize(loss, 0, 1).minimizer

# Plot likelihood
θ_range = 0.1:0.01:1.0
likelihood = [exp(flip_log_like(θ)) for θ in θ_range]

fig = lines(θ_range, likelihood;
	axis = (xlabel = "θ", ylabel = "Likelihood", title = "Likelihood Function"))
vlines!([θ_mle], color = :red, linewidth = 2, label = "MLE")
axislegend()
fig
```

### Bayesian Analysis with Beta Prior

```{julia}
# Choose Beta prior
prior_dist = Beta(5, 5)

# The posterior for Beta-Binomial is analytically known
posterior_dist = Beta(prior_dist.α + n_heads, prior_dist.β + N - n_heads)

# Plot prior, likelihood, and posterior
θ_fine = 0:0.01:1
fig = lines(θ_fine, pdf.(prior_dist, θ_fine),
	label = "Prior", linewidth = 2,
	axis = (xlabel = "θ", ylabel = "Density", title = "Bayesian Coin Flip Analysis"))

likelihood_normalized = [exp(flip_log_like(θ)) for θ in θ_fine]
likelihood_normalized = likelihood_normalized ./ maximum(likelihood_normalized) .* maximum(pdf.(prior_dist, θ_fine))
lines!(θ_fine, likelihood_normalized, label = "Likelihood (scaled)", linewidth = 2)

lines!(θ_fine, pdf.(posterior_dist, θ_fine),
	label = "Posterior", linewidth = 2)

vlines!([θ_mle], color = :red, linewidth = 2, linestyle = :dash, label = "MLE")
axislegend()
fig
```

## Markov Chain Monte Carlo (MCMC)

### Simple Metropolis-Hastings Algorithm

```{julia}
# Define log posterior
log_posterior(θ) = logpdf(prior_dist, θ) + flip_log_like(θ)

# Simple Metropolis-Hastings sampler
function simple_mcmc(n_samples; initial_θ = 0.5)
	samples = Float64[]
	current_θ = initial_θ

	for i in 1:n_samples
		# Propose new value from uniform distribution
		proposal = rand(Uniform(0, 1))

		# Calculate acceptance probability
		log_α = log_posterior(proposal) - log_posterior(current_θ)
		α = min(1, exp(log_α))

		# Accept or reject
		if rand() < α
			current_θ = proposal
		end

		push!(samples, current_θ)
	end

	return samples
end

# Run sampler
mcmc_samples = simple_mcmc(10_000)

# Compare with analytical solution
fig = hist(mcmc_samples, bins = 50, normalization = :pdf,
	label = "MCMC Samples",
	axis = (xlabel = "θ", ylabel = "Density", title = "MCMC vs Analytical Posterior"))

θ_plot = 0:0.001:1
lines!(θ_plot, pdf.(posterior_dist, θ_plot),
	linewidth = 3, label = "Analytical Posterior")
axislegend()
fig
```

## Turing.jl for Modern Bayesian Inference

### Model Specification

```{julia}
# Define Bayesian model in Turing
@model function coinflip_model(y)
	# Prior
	θ ~ Beta(5, 5)

	# Likelihood  
	y .~ Bernoulli(θ)
end

# Sample from posterior
model = coinflip_model(heads)
chain = sample(model, NUTS(), 2_000)

summarystats(chain)
```

### Visualization

```{julia}
# Extract samples
θ_samples = chain[:θ]

fig = hist(θ_samples, bins = 50, normalization = :pdf,
	label = "Turing Samples",
	axis = (xlabel = "θ", ylabel = "Density", title = "Turing.jl vs Analytical Posterior"))

lines!(θ_plot, pdf.(posterior_dist, θ_plot),
	linewidth = 3, label = "Analytical Posterior")
axislegend()
fig
```

## Case Study: Storm Surge Distribution

This example demonstrates Bayesian inference for continuous parameters using real climate data.

### Data Preparation  

```{julia}
# Create synthetic storm surge data (representing annual maxima)
Random.seed!(456)
true_μ = 1.2
true_σ = 0.3
n_years = 30

# Generate synthetic data
surge_data = rand(LogNormal(true_μ, true_σ), n_years)

fig = scatter(1:n_years, surge_data,
	axis = (xlabel = "Year", ylabel = "Annual Max Surge Height (m)",
		title = "Synthetic Storm Surge Data"))
```

### Bayesian Model

```{julia}
# Define Bayesian model for LogNormal distribution
@model function lognormal_model(y, μ_prior, σ_prior)
	μ ~ μ_prior
	σ ~ σ_prior

	y .~ LogNormal(μ, σ)
end
```

### Prior Predictive Checks

```{julia}
# Start with diffuse priors
μ_prior = Normal(0, 10)
σ_prior = truncated(Normal(0, 10), 0, Inf)

# Sample from prior predictive distribution
prior_samples = sample(lognormal_model(surge_data, μ_prior, σ_prior), Prior(), 1_000)

# Plot some prior predictive realizations
fig = lines(1:n_years, surge_data, linewidth = 3, label = "Observed Data",
	axis = (xlabel = "Year", ylabel = "Surge Height (m)",
		title = "Prior Predictive Checks"))

for i in 1:10
	μ_sample = prior_samples[:μ][i]
	σ_sample = prior_samples[:σ][i]
	simulated = rand(LogNormal(μ_sample, σ_sample), n_years)
	lines!(1:n_years, simulated, color = (:blue, 0.3), linewidth = 1)
end

# Add label for simulated data
lines!(1:n_years, rand(LogNormal(prior_samples[:μ][1], prior_samples[:σ][1]), n_years),
	color = (:blue, 0.3), linewidth = 1, label = "Prior Predictive")
axislegend()
fig
```

### Posterior Inference

```{julia}
# Use more informative priors based on domain knowledge
μ_prior_informed = Normal(1, 1)
σ_prior_informed = truncated(Normal(0, 0.5), 0, Inf)

# Sample posterior
model = lognormal_model(surge_data, μ_prior_informed, σ_prior_informed)
posterior_chain = sample(model, NUTS(), 2_000)

summarystats(posterior_chain)
```

### Return Period Analysis with Uncertainty

```{julia}
# Calculate return levels with uncertainty
return_periods = [2, 5, 10, 25, 50, 100]
exceedance_probs = 1 .- 1 ./ return_periods

# Extract posterior samples
μ_posterior = posterior_chain[:μ]
σ_posterior = posterior_chain[:σ]

# Calculate return level distributions
return_level_samples = []
for (i, aep) in enumerate(exceedance_probs)
	levels = [quantile(LogNormal(μ_posterior[j], σ_posterior[j]), aep)
			  for j in 1:length(μ_posterior)]
	push!(return_level_samples, levels)
end

# Plot return level uncertainty
fig = scatter(return_periods, [quantile(levels, 0.5) for levels in return_level_samples],
	axis = (xlabel = "Return Period (years)", ylabel = "Return Level (m)",
		title = "Return Levels with Uncertainty", xscale = log10),
	label = "Median", markersize = 8)

# Add uncertainty bands  
for (i, levels) in enumerate(return_level_samples)
	lower = quantile(levels, 0.1)
	upper = quantile(levels, 0.9)
	# Add error bars
	scatter!([return_periods[i]], [quantile(levels, 0.5)],
		yerror = [quantile(levels, 0.5) - lower, upper - quantile(levels, 0.5)],
		color = :blue, alpha = 0.5)
end

# Add true values for comparison
true_levels = [quantile(LogNormal(true_μ, true_σ), aep) for aep in exceedance_probs]
lines!(return_periods, true_levels, color = :red, linewidth = 2, label = "True Values")

axislegend()
fig
```

## Key Takeaways

1. **Prior Information Matters**: The rare disease example shows how prior probabilities dramatically affect conclusions
2. **MCMC Enables Complex Inference**: Modern samplers like NUTS can handle high-dimensional, complex posterior distributions
3. **Model Checking is Crucial**: Prior predictive checks help validate model assumptions
4. **Uncertainty Quantification**: Bayesian methods naturally quantify parameter uncertainty, crucial for risk analysis
5. **Computational Tools**: Turing.jl provides a powerful, flexible framework for Bayesian modeling

The combination of principled uncertainty quantification and modern computational tools makes Bayesian methods particularly valuable for climate risk assessment.