---
title: Policy Search & Optimization ✏️
status: "draft"
---

## See First {.unnumbered}

This chapter builds on concepts from:
- [Optimization](/chapters/fundamentals/optimization.qmd)
- [Expectations and Discounting](/chapters/risk/expectations-cost-benefit.qmd)

## Learning Objectives {.unnumbered}

- Formulate policy design problems as optimization tasks.
- Explore multi-objective policy search (e.g., cost, emissions, equity).
- Evaluate strategies (carbon taxes, cap-and-trade) under uncertainty.

You'll want to refer heavily to the chapter on [optimization](../fundamentals/optimization.qmd)

## Overview

### Review of notation

Notation for our system dynamics:

- State of the world: encapsulates all inputs to our model
- Decisions: can be very simple (how high do we elevate a house right now?) or very complex (spatial and/or temporal optimization problems)
- Outcomes: can be a single number (scalar) or a vector if there are multiple outcomes we care about

### Key components of an optimization problem

1. Objective function
1. Constraints
1. Decision variables

::: {.callout-tip}
## Reflect
To what extent is this [in]consistent with exploratory modeling?
:::

### Why optimize?

Large action spaces (many decision variables) make it difficult to find the best solution by trial and error.

::: {.callout-important}
Today we'll say _optimization_ but even an exact solution is only optimal in our model, not the real world.
I prefer the term _policy search_ which emphasizes the use of computers to suggest promising strategies.
:::

## Optimization in the wild

### Where have you seen optimization used?

::: {.callout-tip}
## Reflect

Take 2-3 minutes, then share.
:::

### Linear programming

Find a vector $\mathbf{x}$ that maximizes $c^T \mathbf{x}$ subject to $A \mathbf{x} \leq \mathbf{b}$ and $\mathbf{x} \geq 0$

1. **Limitations:** requires strong assumptions (is linearizing your function a good approximation?)
1. **Strengths:** very fast (can scale to large problems)
1. **Examples:** how much should each pump in a water distribution network be run at a given time step to maintain pressure?

### Linear programming with discrete decisions

- Fixed costs create discontinuities in the objective function
- Example: which electricity generators should be on/off?
- Need to create new indicator variables which flag on/off status: $\mathbb{I}_i = \begin{cases} 0 & \textrm{off} \\ 1 & \textrm{on} \end{cases}$.
- Can be solved with mixed-integer linear programming (MILP)

### Gradient descent
If you have a differentiable function, you can use gradient descent to find the minimum.

$$
\mathbf{x}_{n+1} = \mathbf{x}_n - \alpha \nabla f(\mathbf{x}_n)
$$

### Simulation-optimization

- **Strengths:** can handle complex, non-linear systems (model can be a black box)
- **Limitations:** slow ("guess and check"), rely on "heuristics" to decide a solution is good enough
- **Examples:** design of water resource systems under uncertainty

## Key points

1. Optimization can be used at a high level (e.g., system design) or can be embedded in a problem (e.g., operations at each time step).
1. Every optimization problem has an objective and decision variables. Many have constraints.
1. Optimization is a field, with many techniques.
1. In this course, I want you to understand and critique how optimization problems are framed in the wild. Take other courses to focus on the techniques.

## Multiobjective Policy Search and Optimization

### Enriching our notation

When we move from single to multiple objectives, our system dynamics notation becomes more complex:
- We may have multiple outcome functions rather than a single scalar outcome

### Single-objective policy search

Using this notation, we want to $\min / \max g(a)$, subject to constraints.

In other words, we want *a single solution* that scores the best according to $g(a)$.

### Objectives can be hard to combine

Sometimes, combining objectives into a single function is difficult.

1. Operating a reservoir to maximize power generation, minimize flood risk, and supply water to a city.
1. Designing a levee to balance cost, financial flood risk, ecological impact, and human safety.

Addressing multiple, sometimes-competing, needs is often called "multi-criteria decision analysis"

### Goals

Goal: find a **set of solutions** that are not **dominated** by any other solution

We call this the *Pareto front* or *Pareto set*.

### Mathematical formulation

$$
\begin{align}
& \min / \max f_m(x), & \quad m = 1, 2, \ldots, M \\
\text{subject to} \quad &g_j(x) \leq 0, &\quad  j = 1, 2, \ldots, J \\
 &h_k(x) = 0, &\quad  k = 1, 2, \ldots, K \\
 &x_i^{(L)} \leq x_i \leq x_i^{(U)}, &\quad  i = 1, 2, \ldots, N
\end{align}
$$

What's new?
- $M$ objective functions
- Lots of notation for constraints

### Dominance

**Concept of Dominance:**
1. **Single-objective**: Goodness of solution defined by objective function value
2. **Multi-objective**: Goodness of solution defined by dominance relationships

**Definition**: Solution $a_1$ dominates solution $a_2$ if:
1. $a_1$ is no worse than $a_2$ in **all** objectives 
2. $a_1$ is **strictly better** than $a_2$ in **at least one** objective

**Example Analysis:**
Consider 5 solutions with objectives $f_1$ (maximize) and $f_2$ (minimize):
- Solution 1: $(2, 2)$
- Solution 2: $(1, 4)$ 
- Solution 3: $(4, 1)$
- Solution 4: $(3, 3)$
- Solution 5: $(5, 2)$

**Dominance relationships:**
- Solution 1 vs 2: Solution 1 dominates (better in $f_1$: 2>1, better in $f_2$: 2<4)
- Solution 1 vs 5: Solution 5 dominates (better in $f_1$: 5>2, same in $f_2$: 2=2)
- Solution 1 vs 4: Neither dominates (trade-offs exist)

Solutions that are not dominated by any other feasible solution form the **Pareto front**.

### Goals of multiobjective optimization

1. Find solutions as close to Pareto front as possible
1. Find solutions as diverse as possible (since infinite points lie along the Pareto front but we can only sample a finite number)

### Implementation Approaches

### Weighted Sum Method

We can *scalarize* the multi-objective problem into a single-objective problem using a weighted sum:

$$
\min F(x) =\sum_{m=1}^M w_m f_m(x)
$$
subject to the same constraints as before.

**Advantages:**
- **Simplicity**: Easy to understand and implement
- **Computational efficiency**: Can use existing single-objective optimization algorithms
- **Pareto front exploration**: Can vary weights systematically to explore trade-offs

**Disadvantages:**
- **Weight selection**: Requires a priori knowledge of preferences
- **Pareto front coverage**: May miss parts of the Pareto front, especially in non-convex regions
- **Uniform weight distribution**: Does not guarantee uniform distribution of solutions along Pareto front

**Convex vs. Non-Convex Pareto Fronts:**

For **convex** Pareto fronts, the weighted sum method can find any point on the front by varying weights.

For **non-convex** Pareto fronts, the weighted sum method cannot find solutions in concave regions - certain trade-offs are mathematically unreachable regardless of weight selection.

This limitation motivates the need for population-based methods like genetic algorithms.

### Genetic Algorithms for Multi-Objective Optimization

**Evolutionary Approach:**
Genetic algorithms are particularly well-suited for multi-objective optimization because they work with **populations** of solutions rather than single points.

**Core Principles:**
1. **Population-based**: GAs operate on a set ("population" or "generation") of candidate solutions
2. **Evolutionary inspiration**: The best solutions are more likely to survive and reproduce
3. **Fitness evaluation**: Compute a *fitness score* for each solution based on objectives and diversity
4. **Selection and reproduction**: Use fitness scores to select solutions for reproduction (crossover)
5. **Mutation**: Add controlled noise (mutation) to create the next "generation"
6. **Algorithmic variety**: Many specific algorithms exist (NSGA-II, SPEA2, etc.)

**Multi-Objective Fitness:**
Unlike single-objective GAs, multi-objective versions must balance:
- **Convergence**: Solutions should be close to the true Pareto front
- **Diversity**: Solutions should be well-distributed along the Pareto front

**Selection Mechanisms:**
- **Non-dominated sorting**: Rank solutions by dominance levels
- **Crowding distance**: Maintain diversity by favoring solutions in less crowded regions
- **Archive maintenance**: Preserve best non-dominated solutions across generations

**Advantages:**
- **Global search**: Can handle complex, multimodal objective spaces
- **Non-convex fronts**: Can find solutions in concave regions of Pareto fronts
- **No weight specification**: Does not require a priori preference information
- **Population diversity**: Naturally maintains diverse set of trade-off solutions

**Disadvantages:**
- **Computational cost**: Requires many function evaluations
- **Parameter tuning**: Multiple algorithm parameters need careful adjustment
- **Stochastic nature**: Results may vary between runs
- **Convergence uncertainty**: Difficult to guarantee global optimality

### A Population of Trade-off Solutions

**Final Output:**
Multi-objective optimization produces a **set of solutions** rather than a single optimal solution.

**Characteristics:**
1. **Non-dominated solutions**: A set of solutions where no solution dominates any other
2. **Trade-off representation**: Each solution represents a different trade-off between objectives  
3. **Pareto front coverage**: Solutions collectively approximate different parts of the Pareto front

**Interpretation and Value:**
One key insight of multi-objective optimization is that it **maps out the trade-offs** between competing objectives.

This is valuable because:
- **Decision support**: Shows range of feasible trade-offs to decision-makers
- **Trade-off quantification**: Makes explicit the costs of improving one objective at expense of others
- **Robust analysis**: Multiple good solutions provide options under different preference structures
- **Stakeholder engagement**: Different solutions may appeal to different stakeholders or constituencies

**Example Applications:**
- **Reservoir operation**: Trade-offs between flood protection, water supply, and hydropower generation
- **Urban planning**: Balance between development density, green space, and transportation access
- **Climate policy**: Trade-offs between mitigation costs, emission reductions, and economic impacts

### Convergence Assessment and Quality Control

**Challenge of Heuristic Methods:**
Genetic algorithms are not exact optimization methods.
They rely on **heuristics** to decide when a solution is "good enough" even if it's not a global optimum.
This creates challenges for assessing solution quality and algorithm convergence.

**Quality Assessment Strategies:**

**1. Multiple Runs with Different Seeds:**
- Repeat optimization with different random initial conditions
- Compare results across runs to assess robustness
- If results vary significantly, may need longer runs or parameter adjustment

**2. Hypervolume Indicator:**
- **Definition**: Volume of objective space dominated by the solution set
- **Purpose**: Measures both convergence (proximity to true front) and diversity (spread along front)  
- **Application**: Track hypervolume over generations to assess convergence
- **Advantages**: Single metric combining multiple quality aspects

**3. Method Comparison:**
- Compare genetic algorithm results to weighted sum method
- Check if GA finds solutions in regions missed by weighted sum (especially non-convex areas)
- Cross-validate using different algorithmic approaches (NSGA-II, SPEA2, etc.)

**4. Benchmark Comparison:**
- Compare optimization results to human-generated or expert solutions
- Verify that algorithm finds solutions that dominate known alternatives
- Use analytical solutions for simplified test problems to validate implementation

**5. Convergence Monitoring:**
- Track solution set changes over generations
- Monitor when new non-dominated solutions stop being found
- Use metrics like generational distance and inverted generational distance

**Practical Implementation Guidelines:**
- **Run length**: Balance computational cost with solution quality
- **Population size**: Larger populations provide better diversity but increase cost
- **Multiple objectives**: More objectives exponentially increase difficulty
- **Archive management**: Maintain external archive of best solutions found

### The Challenge of Many Objectives

**Diminishing Returns from Additional Objectives:**

While it may seem beneficial to include all relevant objectives explicitly, there are significant **drawbacks** to adding more objectives:

**Computational Challenges:**
- **Exponential scaling**: The number of solutions needed grows exponentially with objectives
- **Pareto front explosion**: In high dimensions, most solutions become non-dominated
- **Search difficulty**: Algorithms struggle to maintain diversity across many objectives

**Cognitive and Communication Challenges:**  
- **Conceptual complexity**: Humans cannot easily visualize or understand trade-offs among many objectives
- **Decision paralysis**: Too many options can make decision-making more difficult
- **Communication barriers**: Difficult to present and discuss results with stakeholders

**The "Curse of Dimensionality" in Objective Space:**
As the number of objectives increases, the volume of the Pareto front grows exponentially relative to the volume of the entire objective space.
This makes it increasingly difficult to find truly inferior solutions, reducing the effectiveness of dominance-based selection.

**Practical Guidelines:**

**Objective Consolidation:**
- Combine related objectives into composite indices when appropriate
- Use weighted sums for objectives that can be meaningfully combined
- Focus on the most critical and independent objectives

**Objective Hierarchy:**
- Distinguish between primary objectives (core concerns) and secondary objectives (constraints or preferences)
- Consider using some objectives as constraints rather than explicit objectives
- Implement lexicographic ordering for objectives with clear priority structure

**Rule of Thumb:**
- **2-3 objectives**: Manageable and interpretable
- **4-6 objectives**: Possible but requires careful analysis
- **>6 objectives**: Generally not recommended without specialized techniques

**When Many Objectives Are Necessary:**
- Use techniques like objective reduction or dimensionality reduction in objective space
- Consider interactive optimization where decision-maker preferences guide the search
- Apply many-objective evolutionary algorithms (e.g., NSGA-III) specifically designed for high-dimensional objective spaces

**Conclusion:**
The goal is to find the **minimum number** of objectives that adequately capture the essential trade-offs in the decision problem.
Quality over quantity applies strongly in multi-objective optimization.

## Constraints (political feasibility, budget limits)

*Content to be developed*

## Further Reading {.unnumbered}