---
title: Robustness ✏️
---

## See First {.unnumbered}

This chapter builds on concepts from:
- [Deep Uncertainty and Model Structure](/chapters/risk/deep-uncertainty.qmd)
- [Optimization](/chapters/fundamentals/optimization.qmd)

## Learning Objectives {.unnumbered}

- Address deep uncertainty in climate decision-making.
- Use robust decision-making (RDM) methods to compare strategies across multiple futures.
- Balance robustness vs. optimality in selecting climate actions.

## Robustness motivation

:::: {.columns}
::: {.column width="54%"}
![](../_assets/img/abraham_demandforecast_2020_fig2.jpg)
:::
::: {.column width="44%"}
### The problem

@abraham_demandforecasts:2020 show that water utilities systematically over-estimate future demand.
Using a single, certain, forecast of future water demand might motivate over-building infrastructure.
:::
::::

:::: {.columns}
::: {.column width="54%"}
![](../_assets/img/abraham_demandforecast_2020_fig2.jpg)
:::
::: {.column width="44%"}
### Robustness

We want to make choices / design infrastructure that are **robust** to errors in demand forecasts.
:::
::::

## Definition

> The insensitivity of system design to errors, random or otherwise, in the estimates of those parameters affecting design choice [@matalas:1977]

Mathematical definitions differ dramatically, however [@herman_robustness:2015]!
Today we will discuss some overlapping perspectives and ideas about robustness.

## Bottom-up analysis

1. **Top-down, certain:** experts develop a "best" forecast of future conditions, then choose a design that is optimal under that forecast
1. **Top-down, uncertain:** experts assign likelihoods to uncertain states of the world, then choose a design that optimizes expected performance [@herman_robustness:2015]
1. **Bottom-up:** first **explore** to identify SOWs a solution is vulnerable to, then assess likelihood (more Wednesday!)

## Deep uncertainty and scenario exploration

## Robustness metrics

### Taxonomy

![@herman_robustness:2015](../_assets/img/herman_robustness_2015_fig1.png)

### Regret

Regret measures how sorry you are with your choice.
There are two main definitions [@herman_robustness:2015]:

1. Deviation of a single solution in the real world or a simulated SOW from its baseline (expected) performance
1. Difference between the performance of a solution in the real world or a simulated SOW and the best possible performance in that SOW

### Satisficing

Satisficing measures whether solutions achieve specific minimum requirements, condensing performance into a binary "satisfactory" or "unsatisfactory".

1. With many SOWs, many studies use a **domain criterion**: over what fraction of SOWs does a solution satisfy a performance threshold [@herman_robustness:2015]?
1. *Note:* this is equivalent to asking what is the probability that a solution satisfies a performance threshold, although many people who calculate robustness metrics are allergic to the word "probability"
1. More complex satisficing criteria: see @mcphail_robustness:2019.

## Robust decision-making (RDM), info-gap theory

## Critiques and alternative perspectives

### Parameters?

The robustness metrics we've seen are defined in terms of parameters: we have a model with parameters, and we define SOWs as different values of those parameters.

Is this a good way to quantify our conceptual ideas about robustness?

### Combinations of uncertainties

In practice, we often have a combination of parametric uncertainties and "model structure" uncertainties [@doss-gollin_subjective:2022].
And **not all SOWs are equally likely**!

![](../_assets/img/lsl-evolution.png)

:::: {.columns}
::: {.column width="45%"}
![](../_assets/img/hausfather_scenarios_2020.jpg)
:::
::: {.column width="55%"}
Climate scenario uncertainties are "deep" (more next week!), but it would be a mistake to say we don't know _anything_ and all futures are equally likely [@hausfather_scenarios:2020]
:::
::::

:::: {.columns}
::: {.column width="55%"}
![@doss-gollin_subjective:2022](../_assets/img/lsl-priors-weights.png)
:::
::: {.column width="45%"}
### Alternative perspective

1. Using "prior beliefs" assign likelihoods to different SOWs
1. Use quantitative toolkit (optimization, sensitivity analysis, etc.)
1. Vary prior belefs: a solution that is robust to different **probability distributions** rather than to different **parameter values**.
:::
::::

## Stress testing policies under various climate, economic, and societal conditions

## Trade-offs between robust vs. "best-estimate" solutions

## Further Reading {.unnumbered}